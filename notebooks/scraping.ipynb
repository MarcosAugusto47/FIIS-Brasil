{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import urllib.request as urllib_request\n",
    "import pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_html(input):\n",
    "    return \" \".join(input.split()).replace('> <', '><')\n",
    "\n",
    "## Rotina de scraping\n",
    "### Declara-se a variável cards\n",
    "cards = []\n",
    "\n",
    "###\n",
    "url = 'https://fiis.com.br/lista-de-fundos-imobiliarios/'\n",
    "#headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:79.0) Gecko/20100101 Firefox/79.0'}\n",
    "headers = {'User-Agent': 'xxxx'}\n",
    "req = Request(url, headers = headers)\n",
    "#req = Request(url)\n",
    "response = urlopen(req)\n",
    "html = response.read()\n",
    "html = html.decode('utf-8')\n",
    "html = trata_html(html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Criação de um objeto Beautiful Soup\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "# print(soup.prettify())\n",
    "tickets = soup.findAll('span', {'class': 'ticker'})\n",
    "codigos = []\n",
    "for ticket in tickets:\n",
    "    codigos.append(ticket.get_text().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "codigo = codigos[0]\n",
    "url = 'https://fiis.com.br/' + codigo\n",
    "headers = {'User-Agent': 'xxxx'} # olhar no seu PC\n",
    "req = Request(url, headers = headers)\n",
    "response = urlopen(req)\n",
    "html = response.read()\n",
    "html = html.decode('utf-8')\n",
    "html = trata_html(html)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "items = soup.findAll('span', {'class': 'value'})\n",
    "items = soup.find_all(class_ = 'value')\n",
    "infos = []\n",
    "card = {}\n",
    "for item in items:\n",
    "    infos.append(item.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for codigo in codigos[0:10]:\n",
    "    url = 'https://fiis.com.br/' + codigo\n",
    "    headers = {'User-Agent': 'xxxx'} # olhar no seu PC\n",
    "    req = Request(url, headers = headers)\n",
    "    response = urlopen(req)\n",
    "    html = response.read()\n",
    "    html = html.decode('utf-8')\n",
    "    html = trata_html(html)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    items = soup.find_all(class_ = 'value')\n",
    "    infos = []\n",
    "    card = {}\n",
    "    for item in items:\n",
    "        infos.append(item.get_text())\n",
    "    card['dividend_yield'] = infos[0]\n",
    "    card['ultimo_rendimento'] = infos[1]\n",
    "    card['patrimonio_liquido'] = infos[2]\n",
    "    card['valor_patrimonial_por_cota'] = infos[3]\n",
    "    card['telefone'] = infos[4]\n",
    "    card['email'] = infos[5]\n",
    "    card['site'] = infos[6]\n",
    "    card['name'] = infos[7]\n",
    "    card['tipo_FII'] = infos[8]\n",
    "    card['tipo_ANBIMA'] = infos[9]\n",
    "    card['registro_CVM'] = infos[10]\n",
    "    card['numero_cotas'] = infos[11]\n",
    "    card['numero_cotistas'] = infos[12]\n",
    "    card['CNPJ'] = infos[13]\n",
    "    card['cotacao'] = infos[14]\n",
    "    card['min_52_weeks'] = infos[15]\n",
    "    card['max_52_weeks'] = infos[16]\n",
    "    card['return_12_months'] = infos[17]\n",
    "    card['ticker'] = codigo.upper()\n",
    "    \n",
    "    admin = soup.findAll(\"div\", {\"class\": \"text-wrapper\"})\n",
    "    card['Administrador'] = re.sub(\"ADMINISTRADOR|[0-9].*[0-9]\", \"\", admin[0].get_text())\n",
    "    \n",
    "    # cotacao = soup.findAll(\"div\", {\"class\": \"item quotation\"})\n",
    "    # cotacao = cotacao[0].find(\"span\", {\"class\": \"value\"}).get_text()\n",
    "    \n",
    "    # min52 = soup.findAll(\"div\", {\"class\": \"item min52\"})\n",
    "    # min52 = min52[0].find(\"div\", {\"class\": \"value\"}).get_text()\n",
    "\n",
    "    # max52 = soup.findAll(\"div\", {\"class\": \"item max52\"})\n",
    "    # max52 = max52[0].find(\"div\", {\"class\": \"value\"}).get_text()\n",
    "\n",
    "    # valorizacao12 = soup.findAll(\"div\", {\"class\": \"item val12\"})\n",
    "    # valorizacao12 = valorizacao12[0].find(\"div\", {\"class\": \"value\"}).get_text()\n",
    "    \n",
    "    # card[\"Cotacao Atual\"] = cotacao\n",
    "    # card[\"Min. 52 semanas\"] = min52\n",
    "    # card[\"Max. 52 semanas\"] = max52\n",
    "    # card[\"Valorizacao\"] = valorizacao12\n",
    "    \n",
    "    cards.append(card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cria-se um dataframe com os resultados\n",
    "dataset = pd.DataFrame(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_LIST = ['ultimo_rendimento',\n",
    "                'valor_patrimonial_por_cota',\n",
    "                'numero_cotas',\n",
    "                'numero_cotistas',\n",
    "                'cotacao',\n",
    "                'min_52_weeks',\n",
    "                'max_52_weeks']\n",
    "dataset = dataset.apply(lambda x: x.str.replace(\"R\\\\$|\\\\.\",\"\", regex = True).str.replace(\",\", \".\").astype(float) if x.name in COLUMNS_LIST else x)\n",
    "dataset[\"p_vp\"] = dataset['cotacao'] / dataset['valor_patrimonial_por_cota']\n",
    "#dataset.to_csv('C:/Users/marco/Desktop/Estatistica/fiis_dataset.csv', sep = ';', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
